{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b732fdf-c903-4deb-8fd3-1fe35ff790b3",
   "metadata": {},
   "source": [
    "# üé• Download and transcribe videos from Twitter/X\n",
    "\n",
    "Welcome to this fun and interactive notebook! In this project, we'll implement a local UI that processes videos from Twitter/X, extracts their audio, transcribes it to text, and even translates to English if needed.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Importance\n",
    "\n",
    "Imagine you stumble upon a fascinating video on Twitter/X. Maybe it's a speech, a podcast clip, or someone sharing their thoughts in another language. You want to understand it fully‚Äîget the transcript, maybe translate it to English, and save the results for later.\n",
    "\n",
    "That's exactly what this code does! I'm building a pipeline that:\n",
    "\n",
    "‚úÖ Downloads a video from a Twitter/X URL  \n",
    "‚úÖ Extracts high-quality audio from it  \n",
    "‚úÖ Transcribes the audio to text using the Whisper AI model  \n",
    "‚úÖ Optionally translates the text to English if it's in another language  \n",
    "‚úÖ Saves the results and cleans up temporary files\n",
    "\n",
    "This notebook will guide you through each step, explain what's happening, and let you run the code yourself. Let's get started!\n",
    "\n",
    "---\n",
    "\n",
    "## Required libraries\n",
    "\n",
    "Here are the required libraries and what each does:\n",
    "\n",
    "- `yt_dlp`: Downloads videos from Twitter/X  \n",
    "- `whisper`: Transcribes audio to text with AI  \n",
    "- `torch`: Powers Whisper with GPU acceleration if available  \n",
    "- `deep_translator`: Translates text to other languages  \n",
    "- `gradio`: Is used for creating the web interface   \n",
    "- `ffmpeg`: Extracts high-quality audio from videos (needs to be installed separately)  \n",
    "- Optional:\n",
    "  - `transformers`: For an alternative transcription method  \n",
    "  - `langdetect`: For detecting the language of the transcription\n",
    "\n",
    "\n",
    "###### NB: To begin it's advisable to setup a virtual environment and download all required libraries. Refer to the `README`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89fb85f0-ea63-439f-9704-592b71992806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "import yt_dlp\n",
    "import whisper\n",
    "import torch\n",
    "from deep_translator import GoogleTranslator\n",
    "import argparse\n",
    "import gradio as gr\n",
    "\n",
    "# Conditionally import transformers if available\n",
    "try:\n",
    "    from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "    transformers_available = True\n",
    "except ImportError:\n",
    "    transformers_available = False\n",
    "\n",
    "try:\n",
    "    from langdetect import detect as detect_lang\n",
    "    langdetect_available = True\n",
    "except ImportError:\n",
    "    langdetect_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1111931c-e9f8-4942-8fd6-08987b66981c",
   "metadata": {},
   "source": [
    "## Downloading the Video\n",
    "\n",
    "Our first task is to grab the video from Twitter/X. The `download_twitter_video` function uses `yt_dlp` to download the video (or just its audio if specified). It creates a temporary file if no output path is provided and ensures we get the best quality available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e17835a-a60e-4683-89d5-f977ef9817e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_twitter_video(tweet_url, output_path=None, audio_only=False):\n",
    "    if output_path is None:\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        output_path = os.path.join(temp_dir, \"twitter_video.mp4\")\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'outtmpl': output_path,\n",
    "        'format': 'bestaudio/best' if audio_only else 'best',\n",
    "        'quiet': True,\n",
    "        'no_warnings': True,\n",
    "        'extract_audio': audio_only,\n",
    "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav', 'preferredquality': '192'}] if audio_only else [],\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([tweet_url])\n",
    "        return output_path.replace('.mp4', '.wav') if audio_only else output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading video: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcccddde-3fac-4473-bbb4-e4ac10a11102",
   "metadata": {},
   "source": [
    "#### What's Happening?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- We pass a Twitter/X URL (e.g., https://twitter.com/username/status/123456789).\n",
    "\n",
    "\n",
    "\n",
    "- If no output_path is specified, it creates a temporary file.\n",
    "\n",
    "\n",
    "\n",
    "- The ydl_opts dictionary configures yt_dlp to download the best video or audio quality.\n",
    "\n",
    "\n",
    "\n",
    "- If audio_only is True, it extracts audio as a WAV file with 192kbps quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428ae62-7098-4ec6-8194-7fc558443959",
   "metadata": {},
   "source": [
    "### Extracting Audio\n",
    "\n",
    "Next, we need the audio from the video for transcription. The `extract_audio` function uses `ffmpeg` to pull out the audio as a WAV file with a high sample rate (48kHz) and stereo channels for better transcription accuracy.\n",
    "\n",
    "- The function takes the video file and creates a WAV file (e.g., video.mp4 becomes video.wav).\n",
    "\n",
    "\n",
    "\n",
    "- The `ffmpeg` command specifies high-quality settings: 48kHz sample rate, stereo, and 192kbps bitrate.\n",
    "\n",
    "\n",
    "\n",
    "- If `ffmpeg` fails (e.g., not installed), it returns the video path as a fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e9bdd7-a2aa-40bc-9e29-bffc6ec64fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(video_path, output_audio_path=None):\n",
    "    if output_audio_path is None:\n",
    "        output_audio_path = os.path.splitext(video_path)[0] + \".wav\"\n",
    "    \n",
    "    # audio extraction \n",
    "    command = [\n",
    "        \"ffmpeg\", \"-i\", video_path, \n",
    "        \"-vn\",  \n",
    "        \"-ar\", \"48000\", \n",
    "        \"-ac\", \"2\",  \n",
    "        \"-ab\", \"192k\",  \n",
    "        \"-f\", \"wav\",  \n",
    "        output_audio_path,\n",
    "        \"-y\"  \n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        return output_audio_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error extracting audio: {e}\")\n",
    "        # If ffmpeg fails, return the video path for direct processing\n",
    "        return video_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2cd5e3-590f-47ab-85ca-50610e4af8af",
   "metadata": {},
   "source": [
    "### Transcribing with Whisper\n",
    "\n",
    "Now for the exciting part: turning audio into text! The `transcribe_with_whisper` function uses OpenAI's Whisper model to transcribe the audio. Whisper is a powerful AI model that can handle multiple languages and noisy audio.\n",
    "\n",
    "- We choose a Whisper model size (tiny, base, small, medium, large). Larger models are more accurate but slower.\n",
    "\n",
    "\n",
    "\n",
    "- Transcription options `beam_size` and `best_of` improve accuracy by exploring multiple transcription possibilities.\n",
    "\n",
    "\n",
    "\n",
    "- The result is the transcribed text, ready for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb9eabe-5858-404e-a1ff-01a91fea410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_whisper(audio_path, model_size=\"medium\", language=None):\n",
    "    \"\"\"\n",
    "    Transcribe audio using Whisper with optimized settings.\n",
    "    \n",
    "    Args:\n",
    "        audio_path: Path to audio file\n",
    "        model_size: Whisper model size (tiny, base, small, medium, large)\n",
    "        language: Source language code if known (improves accuracy)\n",
    "    \n",
    "    Returns:\n",
    "        Transcribed text\n",
    "    \"\"\"\n",
    "    # Check for GPU availability and set device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using {device} for Whisper transcription with {model_size} model\")\n",
    "    \n",
    "    # Load model with specified size\n",
    "    model = whisper.load_model(model_size, device=device)\n",
    "    \n",
    "    # Configure transcription options for better accuracy\n",
    "    transcribe_options = {\n",
    "        \"fp16\": device == \"cuda\",  \n",
    "        \"language\": language,  \n",
    "        \"task\": \"transcribe\",\n",
    "        \"beam_size\": 5,  \n",
    "        \"best_of\": 5\n",
    "    }\n",
    "    \n",
    "    # Remove None values\n",
    "    transcribe_options = {k: v for k, v in transcribe_options.items() if v is not None}\n",
    "    \n",
    "    # Perform transcription\n",
    "    result = model.transcribe(audio_path, **transcribe_options)\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5550e0d-56a7-49a7-97d1-12941813935e",
   "metadata": {},
   "source": [
    "### Alternative Transcription with Transformers\n",
    "\n",
    "For extra reliability, we can use the transformers library to transcribe with Whisper's large-v2 model. This is optional and only runs if transformers is installed and the model size is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18638e61-9d83-47a4-891c-479c8631294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_transformers(audio_path):\n",
    "    \"\"\"Use Transformers pipeline for an alternative transcription option (Whisper large-v2).\"\"\"\n",
    "    if not transformers_available:\n",
    "        print(\"Transformers library not available. Install with: pip install transformers\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Initialize the Whisper model through transformers (provides different implementation)\n",
    "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "        \n",
    "        model_id = \"openai/whisper-large-v2\"\n",
    "        \n",
    "        model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "            model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "        )\n",
    "        model.to(device)\n",
    "        \n",
    "        processor = AutoProcessor.from_pretrained(model_id)\n",
    "        \n",
    "        pipe = pipeline(\n",
    "            \"automatic-speech-recognition\",\n",
    "            model=model,\n",
    "            tokenizer=processor.tokenizer,\n",
    "            feature_extractor=processor.feature_extractor,\n",
    "            max_new_tokens=128,\n",
    "            chunk_length_s=30,\n",
    "            batch_size=16,\n",
    "            return_timestamps=True,\n",
    "            torch_dtype=torch_dtype,\n",
    "            device=device,\n",
    "        )\n",
    "        \n",
    "        result = pipe(audio_path)\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in transformers transcription: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd519c8d-d1cf-4603-a9be-27eeab1b6106",
   "metadata": {},
   "source": [
    "### Detecting and Translating the Language\n",
    "\n",
    "If the transcript isn't in English, we want to translate it. First, we detect the language with `langdetect` (if available). Then, we use `GoogleTranslator` to translate the text.\n",
    "\n",
    "- `detect_language` identifies the language of the transcript (e.g., es for Spanish).\n",
    "\n",
    "\n",
    "\n",
    "- `translate_text` translates the text to the target language (default: English). For long texts (>500 characters), it splits them into chunks for better accuracy.\n",
    "\n",
    "\n",
    "\n",
    "- `split_text_into_chunks` breaks text into sentence-sized pieces to avoid translation errors with long texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f95886-31be-4c99-a4fe-3203c9485590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    \"\"\"Attempt to detect the language of the text for better translation.\"\"\"\n",
    "    if not langdetect_available:\n",
    "        return \"auto\"\n",
    "    \n",
    "    try:\n",
    "        return detect_lang(text)\n",
    "    except:\n",
    "        return \"auto\" \n",
    "\n",
    "def translate_text(text, source='auto', target='en', use_advanced=True):\n",
    "    \"\"\"\n",
    "    Translate text with enhanced accuracy.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to translate\n",
    "        source: Source language code or 'auto' for auto-detection\n",
    "        target: Target language code\n",
    "        use_advanced: Whether to use advanced techniques\n",
    "    \n",
    "    Returns:\n",
    "        Translated text\n",
    "    \"\"\"\n",
    "    if not text or text.strip() == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    # Simple translation with Google Translator\n",
    "    try:\n",
    "        translated = GoogleTranslator(source=source, target=target).translate(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return text\n",
    "    \n",
    "    if not use_advanced:\n",
    "        return translated\n",
    "    \n",
    "    # For improved accuracy, split long text into chunks and translate separately\n",
    "    if len(text) > 500:\n",
    "        chunks = split_text_into_chunks(text, 500)\n",
    "        translations = []\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            chunk_translation = GoogleTranslator(source=source, target=target).translate(chunk)\n",
    "            translations.append(chunk_translation)\n",
    "        \n",
    "        return \" \".join(translations)\n",
    "    \n",
    "    return translated\n",
    "\n",
    "def split_text_into_chunks(text, max_chunk_size):\n",
    "    \"\"\"Split text into chunks at sentence boundaries.\"\"\"\n",
    "    sentences = text.replace(\"„ÄÇ\", \".\").replace(\"ÔºÅ\", \"!\").replace(\"Ôºü\", \"?\").split(\".\")\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if not sentence.strip():\n",
    "            continue\n",
    "            \n",
    "        sentence = sentence.strip() + \".\"\n",
    "        \n",
    "        if len(current_chunk) + len(sentence) <= max_chunk_size:\n",
    "            current_chunk += \" \" + sentence\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "        \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98050b85-9c58-4b6f-8eef-3ef0cd3c8043",
   "metadata": {},
   "source": [
    "### Putting It All Together\n",
    "\n",
    "The `process_twitter_video` function ties everything together. It takes a Twitter/X URL, downloads the video, extracts audio, transcribes it, translates if needed, and saves the results. The function orchestrates the entire pipeline: download, extract, transcribe, translate, and save. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f40e65-973c-4e76-82b1-33940055d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_twitter_video(tweet_url, model_size=\"medium\", output_dir=None, target_language=\"en\"):\n",
    "    \"\"\"\n",
    "    Process Twitter video without using argparse (for Jupyter compatibility).\n",
    "    \n",
    "    Args:\n",
    "        tweet_url: URL of the Twitter/X video\n",
    "        model_size: Whisper model size to use\n",
    "        output_dir: Directory to save output files\n",
    "        target_language: Target language for translation\n",
    "    \"\"\"\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    output_file = os.path.join(output_dir, \"twitter_video.mp4\") if output_dir else None\n",
    "    \n",
    "    print(\"\\n=== Processing Twitter Video ===\")\n",
    "    print(f\"Downloading video from: {tweet_url}\")\n",
    "    video_path = download_twitter_video(tweet_url, output_path=output_file)\n",
    "    \n",
    "    print(\"Extracting high-quality audio...\")\n",
    "    audio_path = extract_audio(video_path)\n",
    "    \n",
    "    print(f\"Transcribing audio using Whisper {model_size} model...\")\n",
    "    whisper_transcript = transcribe_with_whisper(audio_path, model_size=model_size)\n",
    "    \n",
    "    # Optional: Try alternative transcription as well for comparison\n",
    "    transformer_transcript = None\n",
    "    if model_size == \"large\" and transformers_available:\n",
    "        print(\"Performing alternative transcription with Transformers...\")\n",
    "        transformer_transcript = transcribe_with_transformers(audio_path)\n",
    "    \n",
    "    # Detect source language for better translation\n",
    "    source_language = detect_language(whisper_transcript)\n",
    "    if source_language != \"en\" and target_language == \"en\":\n",
    "        print(f\"Detected source language: {source_language}\")\n",
    "        print(\"Translating to English...\")\n",
    "        translated_text = translate_text(\n",
    "            whisper_transcript, \n",
    "            source=source_language, \n",
    "            target=target_language, \n",
    "            use_advanced=True\n",
    "        )\n",
    "    else:\n",
    "        translated_text = whisper_transcript\n",
    "    \n",
    "    # Save results to files if output directory specified\n",
    "    if output_dir:\n",
    "        with open(os.path.join(output_dir, \"transcript.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(whisper_transcript)\n",
    "        \n",
    "        with open(os.path.join(output_dir, \"translated.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(translated_text)\n",
    "        \n",
    "        if transformer_transcript:\n",
    "            with open(os.path.join(output_dir, \"alt_transcript.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(transformer_transcript)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n=== Original Transcript ===\")\n",
    "    print(whisper_transcript)\n",
    "    \n",
    "    if source_language != \"en\" and target_language == \"en\":\n",
    "        print(\"\\n=== Translated Transcript ===\")\n",
    "        print(translated_text)\n",
    "    \n",
    "    # Clean up temporary files\n",
    "    if not output_dir:\n",
    "        try:\n",
    "            os.remove(audio_path)\n",
    "            if video_path != output_file:  # Only remove if it's a temp file\n",
    "                os.remove(video_path)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return {\n",
    "        \"transcript\": whisper_transcript,\n",
    "        \"translated\": translated_text,\n",
    "        \"alt_transcript\": transformer_transcript\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395461f8-855b-4bd7-8a47-10030a6f6763",
   "metadata": {},
   "source": [
    "### Adding Gradio Interface\n",
    "\n",
    "We've added a Gradio interface! Gradio lets you create a web-based UI where users can paste a Twitter/X video URL and instantly see the transcribed and translated text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e1963f-cd9b-47fa-a1cd-5652f7f0fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Twitter Video ===\n",
      "Downloading video from: https://x.com/partidazocope/status/1907843479113240654\n",
      "Extracting high-quality audio...\n",
      "Transcribing audio using Whisper medium model...\n",
      "Using cpu for Whisper transcription with medium model\n",
      "Detected source language: ca\n",
      "Translating to English...\n",
      "\n",
      "=== Original Transcript ===\n",
      " Tornant a aquella versi√≥, doncs el Bar√ßa s√≠ que ha millorat. Gr√†cies. S√≠. Tamb√© et diria que crec que cap de les dues pannes ha sigut prou bona. I llavors, per molt que el gol hagi vingut en aquesta relaci√≥, que argumentes que va ser igual el dia de Wolfsburg, penso que vol dir que √©s una panna que ha sigut prou bona com per deixar el Madrid tancat a la seva √†rea i a m√©s. Avui busc√†vem un p√®l diferent. El Madrid ens defensa la seva banda dreta bastant tancada i llavors vol√≠em estirar bastant a la frida all√† per tenir algun avantatge i trobar bones seq√ºeles per davant, que √©s un dels m√©s escriptus que t√© Frido. Com he dit, no ha sigut perfecte el nostre partit, no m'ha estat molt precis a partir d'aquestes receptions fora i els canvis han vingut a la mitjana part, intentant trobar una millor versi√≥ per aquell costat i aix√≠ hem perdut.\n",
      "\n",
      "=== Translated Transcript ===\n",
      "Returning to that version, because Bar√ßa did improve. Thank you. Yes. I would also tell you that I think neither panel has been good enough. And then, no matter how much the goal came in this relationship, you argue that Wolfsburg's the same, I think it means that it is a panna that has been good enough to leave Madrid closed in its area and also. Today we were looking for a different hair. Madrid defends its right side quite closed and then we wanted to stretch the Frida there to have some advantage and find good sequels ahead, which is one of the most frido desats. As I said, our party was not perfect, I was not very accurate from these receptions outside and the changes have come to the average part, trying to find a better version on that side and so we have lost.\n"
     ]
    }
   ],
   "source": [
    "def gradio_interface(tweet_url):\n",
    "    try:\n",
    "        result = process_twitter_video(tweet_url, model_size=\"medium\", output_dir=\"output\")\n",
    "        return result[\"transcript\"], result[\"translated\"]\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", \"\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Textbox(label=\"Enter Twitter/X Video URL\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Original Transcript\"),\n",
    "        gr.Textbox(label=\"Translated Transcript (English)\")\n",
    "    ],\n",
    "    title=\"Twitter Video English Transcriber\",\n",
    "    description=\"Paste a Twitter/X video link and get the transcribed and translated speech using Whisper.\"\n",
    ")\n",
    "\n",
    "demo.launch(inbrowser=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eedcee3-5126-407f-ac8f-0de7505a798b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
